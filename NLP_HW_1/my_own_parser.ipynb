{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1oXqA8L7XRvO"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fake_useragent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxqVia3lYKos",
        "outputId": "87e6bfe7-d3cb-4d7e-a218-2d565023ad6e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fake_useragent in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# подгрузим один из методов этой библиотеки\n",
        "from fake_useragent import UserAgent"
      ],
      "metadata": {
        "id": "gkjlpKXpYTYn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hrefs_from_page(page_number):\n",
        "  page_url = f'https://shazoo.ru/tags/590/anime?page={page_number}'\n",
        "  response = requests.get(page_url, headers={'User-Agent': UserAgent().chrome})\n",
        "\n",
        "  if not response.ok:\n",
        "    return []\n",
        "\n",
        "  html = response.content\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  obj = soup.findAll('h4', attrs={'class': 'leading-normal'})\n",
        "\n",
        "  hrefs_list = []\n",
        "\n",
        "  for i, el in enumerate(obj):\n",
        "    hrefs_list.append(el.a['href'])\n",
        "\n",
        "  return hrefs_list"
      ],
      "metadata": {
        "id": "zm8m8fwMafxp"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_data_from_post(post_url):\n",
        "  response = requests.get(post_url, headers={'User-Agent': UserAgent().chrome})\n",
        "\n",
        "  html = response.content\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "  title_obj = soup.find('h1', attrs={'class': 'sm:max-w-4xl text-xl sm:text-3xl leading-tight font-bold break-words dark:text-gray-300'})\n",
        "  title = title_obj.text\n",
        "\n",
        "\n",
        "  tags_list = []\n",
        "  tags_obj = soup.findAll('ul', attrs={'class': 'flex flex-wrap gap-x-2 gap-y-1'})\n",
        "  tags_li_soup = BeautifulSoup(str(tags_obj), 'html.parser')\n",
        "  tags_li_list = tags_li_soup.findAll('li' )\n",
        "\n",
        "  for el in tags_li_list:\n",
        "    tags_list.append(el.a.text)\n",
        "\n",
        "  time_name_obj = soup.find('div', attrs={'class': 'flex items-center gap-2'})\n",
        "  time = time_name_obj.time.text\n",
        "  author = BeautifulSoup(str(time_name_obj), 'html.parser').findAll('a')[1].text\n",
        "\n",
        "  return {'title': title, 'tags': tags_list, 'time': time, 'author': author}\n"
      ],
      "metadata": {
        "id": "ixGanSMIdca5"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data(n_pages=1, start_page=0):\n",
        "  df = pd.DataFrame(columns=[\"title\", \"tags\", \"time\", \"author\"])\n",
        "\n",
        "  for i in range(start_page, n_pages):\n",
        "    hrefs_list = get_hrefs_from_page(i)\n",
        "\n",
        "    for post in hrefs_list:\n",
        "      post_data = get_all_data_from_post(post)\n",
        "      df = pd.concat([df, pd.DataFrame([post_data])], ignore_index=True)\n",
        "\n",
        "      time.sleep(1)\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "4Isi9hG7iuTA"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = parse_data(n_pages=10)\n",
        "\n",
        "df.to_csv(\"ten_pages_result.csv\")"
      ],
      "metadata": {
        "id": "4hQGxXs1rrbP"
      },
      "execution_count": 150,
      "outputs": []
    }
  ]
}